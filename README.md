♿ AI-Powered Accessibility Toolkit

This repository contains the research prototype developed during my time as an AI & Accessibility Research Assistant. The project focuses on improving digital accessibility for users with visual and physical impairments using AI-powered tools and human-centered design.

🚀 Overview

This toolkit enhances web accessibility by integrating:
	•	OCR capabilities to extract and read screen content
	•	Multimodal input systems like voice commands and tactile feedback
	•	High-contrast and keyboard-navigable form components
	•	Screen reader optimization following ARIA and WCAG standards

🧠 Key Features
	•	🔍 Optical Character Recognition (OCR) using Tesseract.js
	•	🗣️ Voice Command Support via the Web Speech API
	•	🎛️ Haptics API for tactile feedback
	•	♿ Enhanced Form Accessibility with ARIA labeling and keyboard navigation
	•	🧪 Human-Centered Design Audits using personas and usability heuristics

🛠 Tech Stack
	•	JavaScript / HTML / CSS
	•	Tesseract.js
	•	Web Speech API
	•	NVDA / VoiceOver for screen reader testing
	•	Haptics API
	•	ARIA & WCAG guidelines

📈 Outcomes
	•	Improved form submission success rates in usability testing
	•	Reduced accessibility failures through iterative audits
	•	Prototyped tools evaluated by users across 3 major assistive technologies

📌 Status

This project is a research prototype. Code is provided as a reference and starting point for future accessibility work. Some features are experimental and not production-ready.
